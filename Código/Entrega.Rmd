---
title: "Predicci√≥n de la Pobreza en Colombia - Taller 2 BDML"
author: "Sara Rocio Rojas y Lina Mar√≠a √Ålvarez"
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: true
    theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# 1. Introducci√≥n

La pobreza sigue siendo una de las problem√°ticas m√°s relevantes en la formulaci√≥n de pol√≠ticas p√∫blicas en Colombia. Este documento presenta el desarrollo del Taller 2 de la materia Big Data y Machine Learning (ECON4676), cuyo objetivo es construir un modelo predictivo para identificar hogares en situaci√≥n de pobreza, a partir de datos suministrados por el DANE. Usamos algoritmos de clasificaci√≥n y abordamos aspectos como desbalance de clases, tuning de hiperpar√°metros y comparaci√≥n de modelos. La evaluaci√≥n de desempe√±o se realiza con la m√©trica F1-score y las predicciones son validadas en la plataforma Kaggle.

# 2. Datos

## 2.1 Descarga de las bases de datos

```{r}
train_p <- read_csv("https://www.dropbox.com/scl/fi/pch52dyx8gilx4rtvmgnw/train_personas.csv?rlkey=tfzax7opjw39va52wf5orz5od&st=aybcoq48&dl=1") %>% clean_names()
train_h <- read_csv("https://www.dropbox.com/scl/fi/kzpccqa6gwtzx0e79iqct/train_hogares.csv?rlkey=ala8b4z6u295zan684zw0zyfb&st=slkkf6kt&dl=1") %>% clean_names()
test_p  <- read_csv("https://www.dropbox.com/scl/fi/bxuc9befzrbt27ajxlpvu/test_personas.csv?rlkey=jh1d6jru4f0jx8ldnqyqshmvh&st=i70qnf7j&dl=1") %>% clean_names()
test_h  <- read_csv("https://www.dropbox.com/scl/fi/sakjsyqp7x7164h68pmam/test_hogares.csv?rlkey=sh8hs0rt1so4cufav0yo8btom&st=t51wnslq&dl=1") %>% clean_names()
```

Este bloque descarga directamente desde Dropbox las cuatro bases proporcionadas para el taller: `train_personas`, `train_hogares`, `test_personas` y `test_hogares`, y las estandariza con `clean_names()` para trabajar con nombres de variables consistentes en R.

## 2.2 Preparaci√≥n de la muestra

```{r}
#-------------------------------------------------------------------------#
# ORGANIZACI√ìN DE LA DATA Y UNI√ìN DE BASES
#-------------------------------------------------------------------------#

# Train:
vars_hogar_extra <- train_p %>%
  mutate(
    edad_laboral = p6040 >= 12 & p6040 <= 65,
    mujer = ifelse(p6020 == 2, 1, 0),
    menor_6 = ifelse(p6040 < 6, 1, 0),
    inactivo_pet = ifelse(edad_laboral, ina, NA)
  ) %>%
  group_by(id) %>%
  summarise(
    n_personas = n(),
    n_ninos = sum(p6040 < 12, na.rm = TRUE),
    n_mayores = sum(p6040 >= 65, na.rm = TRUE),
    prop_ocupados = sum(oc == 1 & edad_laboral, na.rm = TRUE) / sum(edad_laboral, na.rm = TRUE),
    educacion_max = max(p6210, na.rm = TRUE),
    educacion_prom = mean(p6210, na.rm = TRUE),
    edad_jefe = p6040[orden == 1],
    sexo_jefe = p6020[orden == 1],
    n_mujeres = sum(mujer, na.rm = TRUE),
    n_menores_6 = sum(menor_6, na.rm = TRUE),
    ocupados_total = sum(oc == 1, na.rm = TRUE),
    prop_inactivos_pet = sum(inactivo_pet == 1, na.rm = TRUE) / sum(!is.na(inactivo_pet))
  )

train_modelo_ext <- train_h %>%
  left_join(vars_hogar_extra, by = "id")

vars_modelo_ext <- train_modelo_ext %>%
  select(
    pobre,
    n_personas, n_ninos, n_mayores, prop_ocupados,
    educacion_max, educacion_prom, edad_jefe, sexo_jefe,
    n_mujeres, n_menores_6, ocupados_total, prop_inactivos_pet
  ) %>%
  mutate(across(.cols = everything(), .fns = ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))

vars_modelo_ext$pobre = as.factor(vars_modelo_ext$pobre)

# Test:
vars_test_ext <- test_p %>%
  mutate(
    edad_laboral = p6040 >= 12 & p6040 <= 65,
    mujer = ifelse(p6020 == 2, 1, 0),
    menor_6 = ifelse(p6040 < 6, 1, 0),
    inactivo_pet = ifelse(edad_laboral, ina, NA)
  ) %>%
  group_by(id) %>%
  summarise(
    n_personas = n(),
    n_ninos = sum(p6040 < 12, na.rm = TRUE),
    n_mayores = sum(p6040 >= 65, na.rm = TRUE),
    prop_ocupados = sum(oc == 1 & edad_laboral, na.rm = TRUE) / sum(edad_laboral, na.rm = TRUE),
    educacion_max = max(p6210, na.rm = TRUE),
    educacion_prom = mean(p6210, na.rm = TRUE),
    edad_jefe = p6040[orden == 1],
    sexo_jefe = p6020[orden == 1],
    n_mujeres = sum(mujer, na.rm = TRUE),
    n_menores_6 = sum(menor_6, na.rm = TRUE),
    ocupados_total = sum(oc == 1, na.rm = TRUE),
    prop_inactivos_pet = sum(inactivo_pet == 1, na.rm = TRUE) / sum(!is.na(inactivo_pet))
  )

test_modelo_ext <- test_h %>%
  left_join(vars_test_ext, by = "id") %>%
  mutate(across(.cols = -id, .fns = ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))

X_test_ext_full <- model.matrix(~ . - id -1, data = test_modelo_ext)
```
## 2.3 Estad√≠sticas descriptivas y visualizaci√≥n

```{r}
# Este bloque se enfoca √∫nicamente en la creaci√≥n del df para las gr√°ficas exploratorias
# y no ser√° utilizado para el entrenamiento de modelos.

library(forcats)

df <- personas %>%
  group_by(id) %>%
  summarise(
    n_personas = n(),
    mujer = sum(P6020 == 2, na.rm = TRUE),
    hombre = sum(P6020 == 1, na.rm = TRUE),
    ni√±os = sum(P6040 < 12, na.rm = TRUE),
    mayores = sum(P6040 >= 65, na.rm = TRUE),
    ocupados = sum(P6240 == 1, na.rm = TRUE),
    educ_sup = sum(P6210 %in% c(8, 9), na.rm = TRUE),
    edad_promedio = mean(P6040, na.rm = TRUE),
    nivel_educativo = mean(P6210, na.rm = TRUE)
  ) %>%
  mutate(prop_ocupados = ocupados / n_personas)

df <- left_join(hogares, df, by = "id")

# Gr√°ficos: secciones comentadas cada tres visualizaciones

# Tama√±o del hogar, n√∫mero de ocupados y nivel educativo
p1 <- ggplot(df, aes(x = factor(Pobre), y = n_personas)) +
  geom_boxplot(fill = "#0072CE", alpha = 0.6) +
  labs(x = "Pobre", y = "Tama√±o del hogar") +
  theme_minimal()

p2 <- ggplot(df, aes(x = factor(Pobre), y = ocupados)) +
  geom_boxplot(fill = "#E30613", alpha = 0.6) +
  labs(x = "Pobre", y = "Ocupados") +
  theme_minimal()

p3 <- ggplot(df, aes(x = factor(Pobre), y = nivel_educativo)) +
  geom_boxplot(fill = "#F4C300", alpha = 0.6) +
  labs(x = "Pobre", y = "Nivel educativo") +
  theme_minimal()

# Edad promedio, proporci√≥n ocupados y distribuci√≥n del ingreso per c√°pita
p4 <- ggplot(df, aes(x = factor(Pobre), y = edad_promedio)) +
  geom_boxplot(fill = "#F7A600", alpha = 0.6) +
  labs(x = "Pobre", y = "Edad promedio") +
  theme_minimal()

p5 <- ggplot(df, aes(x = factor(Pobre), y = prop_ocupados)) +
  geom_boxplot(fill = "#A0195B", alpha = 0.6) +
  labs(x = "Pobre", y = "Proporci√≥n ocupados") +
  theme_minimal()

p6 <- ggplot(df, aes(x = factor(Pobre), y = Ingpcug)) +
  geom_violin(fill = "#0072CE", alpha = 0.6) +
  scale_y_log10() +
  labs(x = "Pobre", y = "Ingreso per c√°pita (log)") +
  theme_minimal()

# Histogramas de ingreso, nivel educativo y tama√±o del hogar
p7 <- ggplot(df, aes(x = Ingpcug, fill = factor(Pobre))) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 50) +
  scale_x_log10() +
  labs(x = "Ingreso per c√°pita (log)", fill = "Pobre") +
  theme_minimal()

p8 <- df %>%
  count(nivel_educativo) %>%
  filter(!is.na(nivel_educativo)) %>%
  mutate(nivel_educativo = fct_reorder(as.factor(nivel_educativo), n, .desc = TRUE)) %>%
  ggplot(aes(x = nivel_educativo, y = n)) +
  geom_bar(stat = "identity", fill = "#0072CE") +
  labs(x = "Nivel educativo promedio", y = "Frecuencia") +
  theme_minimal()

p9 <- ggplot(df, aes(x = n_personas)) +
  geom_histogram(fill = "#A0195B", bins = 30) +
  labs(x = "Tama√±o del hogar", y = "Frecuencia") +
  theme_minimal()

# Mostrar algunas visualizaciones juntas
(p1 + p2 + p3) / (p4 + p5 + p6)
```

## 3.1 Elastic Net Regularizado

El modelo Elastic Net combina las penalizaciones L1 (Lasso) y L2 (Ridge), lo que permite realizar selecci√≥n de variables y reducir el sobreajuste, especialmente √∫til cuando hay colinealidad. Aqu√≠ se utiliza un `alpha = 0.5` que balancea ambos extremos. Se emplea validaci√≥n cruzada con 5 folds para encontrar el `lambda` √≥ptimo, evaluando el desempe√±o con el √°rea bajo la curva (AUC).

```{r}
X_ext <- model.matrix(pobre ~ . -1, data = vars_modelo_ext)
y_ext <- vars_modelo_ext$pobre

set.seed(123)
modelo_elastic_ext <- cv.glmnet(
  x = X_ext,
  y = y_ext,
  family = "binomial",
  alpha = 0.5,
  nfolds = 5,
  type.measure = "auc"
)

plot(modelo_elastic_ext)
modelo_elastic_ext$lambda.min
```

### üìä CURVA ROC Y AUC

```{r}
roc_elastic_ext <- roc(response = as.numeric(test_modelo_ext$pobre),
                       predictor = test_modelo_ext$prob_pred,
                       levels = c(0,1))

auc(roc_elastic_ext)

plot(roc_elastic_ext, col = "darkgreen", lwd = 2, main = "ROC - Elastic Net Extendido")
abline(a = 0, b = 1, lty = 2, col = "gray")
```

### üíæ GUARDAR PREDICCIONES EN CSV

```{r}
predicciones_ext <- test_modelo_ext %>% select(id, pobre)
write_csv(predicciones_ext, "predicciones_elastic_net_extendido.csv")
```

### üîç COMPARACI√ìN DE DESEMPE√ëO CON MODELO B√ÅSICO

```{r}
roc_basic <- roc(response = as.numeric(test_modelo$pobre),
                 predictor = as.numeric(test_modelo$prob_pred))
auc_basic <- auc(roc_basic)

roc_ext <- roc(response = as.numeric(test_modelo_ext$pobre),
               predictor = as.numeric(test_modelo_ext$prob_pred))
auc_ext <- auc(roc_ext)

pobres_basic <- sum(test_modelo$pobre)
pobres_ext <- sum(test_modelo_ext$pobre)

cat("üîç COMPARACI√ìN DE MODELOS ELASTIC NET\n")
cat("----------------------------------------\n")
cat(sprintf("Modelo B√°sico (7 vars)     | AUC: %.4f | Pobres predichos: %d\n", auc_basic, pobres_basic))
cat(sprintf("Modelo Extendido (+vars)   | AUC: %.4f | Pobres predichos: %d\n", auc_ext, pobres_ext))
```

## 3.2 √Årboles de Clasificaci√≥n (CART)

Los √°rboles de decisi√≥n tipo CART (Classification and Regression Trees) son modelos de clasificaci√≥n que permiten segmentar los datos a trav√©s de reglas de decisi√≥n simples. Una de sus principales ventajas es su **interpretabilidad**, ya que permiten visualizar el proceso de clasificaci√≥n de manera jer√°rquica. En este caso, utilizamos CART para predecir la condici√≥n de pobreza del hogar. A continuaci√≥n se presenta la implementaci√≥n completa:

Se cargan las librer√≠as necesarias:
- `caret`: para entrenamiento y validaci√≥n cruzada.
- `rpart`: para construir √°rboles de clasificaci√≥n.
- `rpart.plot`: para visualizar los √°rboles de decisi√≥n.
- `MLmetrics`: para calcular m√©tricas como el F1 Score.

```{r}
# Cargar librer√≠as necesarias
library(caret)
library(rpart)
install.packages("rpart.plot")
library(rpart.plot)
install.packages("MLmetrics")
library(MLmetrics)

# Entrenamiento inicial del CART b√°sico
modelo_cart <- rpart(
  formula = pobre ~ .,
  data = vars_modelo_ext,
  method = "class",
  parms = list(split = "gini"),
  control = rpart.control(cp = 0.01, minsplit = 20)
)

# Visualizaci√≥n del √°rbol inicial
rpart.plot(
  modelo_cart,
  type = 2,
  extra = 104,
  under = TRUE,
  fallen.leaves = TRUE,
  box.palette = "Blues"
)

# Evaluaci√≥n del modelo
pred_entrenamiento <- predict(modelo_cart, newdata = vars_modelo_ext, type = "class")

f1_cart <- F1_Score(
  y_pred = as.character(pred_entrenamiento),
  y_true = as.character(vars_modelo_ext$pobre),
  positive = "1"
)

print(paste("F1 Score del CART en train:", round(f1_cart, 4)))

# Segundo intento: CART con tuning de hiperpar√°metros
set.seed(123)

ctrl <- trainControl(
  method = "cv",
  number = 5,
  summaryFunction = defaultSummary,
  classProbs = TRUE
)

grid <- expand.grid(cp = seq(0.0001, 0.05, by = 0.002))

vars_modelo_ext <- vars_modelo_ext %>%
  mutate(pobre = factor(pobre, levels = c(0, 1), labels = c("no", "si")))

modelo_cart_cv <- train(
  pobre ~ .,
  data = vars_modelo_ext,
  method = "rpart",
  trControl = ctrl,
  tuneGrid = grid,
  metric = "Accuracy"
)

print(modelo_cart_cv)
plot(modelo_cart_cv)

# √Årbol final podado
rpart.plot(
  modelo_cart_cv$finalModel,
  type = 2,
  extra = 104,
  under = TRUE,
  fallen.leaves = TRUE,
  box.palette = "Blues"
)

# Predicci√≥n y evaluaci√≥n final
pred_entrenamiento <- predict(modelo_cart_cv, newdata = vars_modelo_ext)

f1_cart_cv <- F1_Score(
  y_pred = pred_entrenamiento,
  y_true = vars_modelo_ext$pobre,
  positive = "si"
)

print(paste("F1 Score del CART podado (train):", round(f1_cart_cv, 4)))

confusionMatrix(
  data = pred_entrenamiento,
  reference = vars_modelo_ext$pobre,
  mode = "everything",
  positive = "si"
)
```
## 3.3 Ensamble de Logit y Random Forest

En esta secci√≥n implementamos un modelo de ensamblaje que combina las predicciones de un modelo de regresi√≥n log√≠stica (logit) y un modelo de bosque aleatorio (Random Forest). El objetivo es aprovechar la capacidad explicativa y lineal del logit con la flexibilidad y poder de captura no lineal del Random Forest. Se ajustan ambos modelos, se realiza una combinaci√≥n ponderada de las probabilidades, y se optimiza el peso del ensamblaje mediante validaci√≥n cruzada para maximizar el F1-score.

```{r}
# üéØ ENTRENAMIENTO DEL RF
modelo_final <- ranger(
  formula = pobre ~ . - id,
  data = train_ext,
  probability = TRUE,
  num.trees = 500,
  mtry = 3,
  min.node.size = 20,
  class.weights = c("0" = 1, "1" = 3),
  seed = 123
)

# üéØ ENTRENAMIENTO DEL MODELO LOGIT
modelo_logit <- glm(pobre ~ . - id, data = train_ext_glm, family = binomial)

# üîÆ PREDICCI√ìN SOBRE TEST (probabilidades)
probs_logit <- predict(modelo_logit, newdata = test_ext, type = "response")
probs_rf    <- predict(modelo_final, data = test_ext)$predictions[, "1"]

# ü§ù ENSAMBLE DE PROBABILIDADES (60% RF, 40% Logit)
prob_ensamble <- 0.6 * probs_rf + 0.4 * probs_logit
cutoff_final  <- 0.33
preds         <- ifelse(prob_ensamble > cutoff_final, 1, 0)

# üéØ VALIDACI√ìN CRUZADA DEL PESO DEL ENSAMBLE
train_ext_num <- train_ext %>%
  mutate(pobre = as.numeric(as.character(pobre)))

set.seed(123)
k <- 5
n <- nrow(train_ext_num)
folds <- sample(rep(1:k, length.out = n))
rf_weights <- seq(0.1, 0.9, by = 0.1)
cutoff_ensamble <- 0.33
grid_results <- list()

# üîÅ Grid Search por peso del ensamble
for (w in rf_weights) {
  logit_w <- 1 - w
  fold_metrics <- list()

  for (fold in 1:k) {
    train_fold <- train_ext_num[folds != fold, ]
    val_fold   <- train_ext_num[folds == fold, ]
    train_fold_glm <- train_fold %>% select(-id)
    val_fold_glm   <- val_fold %>% select(-id)

    modelo_rf <- ranger(
      formula = factor(pobre) ~ . - id,
      data = train_fold,
      probability = TRUE,
      num.trees = 500,
      mtry = 3,
      min.node.size = 20,
      class.weights = c("0" = 1, "1" = 3),
      seed = 123
    )
    probs_rf <- predict(modelo_rf, data = val_fold)$predictions[, "1"]

    modelo_logit <- glm(pobre ~ ., data = train_fold_glm, family = binomial)
    probs_logit <- predict(modelo_logit, newdata = val_fold_glm, type = "response")

    prob_final <- w * probs_rf + logit_w * probs_logit
    pred <- ifelse(prob_final > cutoff_ensamble, 1, 0)
    real <- val_fold$pobre

    tp <- sum(pred == 1 & real == 1)
    tn <- sum(pred == 0 & real == 0)
    fp <- sum(pred == 1 & real == 0)
    fn <- sum(pred == 0 & real == 1)

    accuracy  <- (tp + tn) / (tp + tn + fp + fn)
    recall    <- ifelse((tp + fn) == 0, NA, tp / (tp + fn))
    precision <- ifelse((tp + fp) == 0, NA, tp / (tp + fp))
    f1 <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0, NA,
                 2 * (precision * recall) / (precision + recall))

    fold_metrics[[fold]] <- tibble(fold, accuracy, recall, precision, f1)
  }

  resumen <- bind_rows(fold_metrics) %>%
    summarise(across(accuracy:f1, mean, na.rm = TRUE)) %>%
    mutate(rf_weight = w, logit_weight = logit_w)

  grid_results[[length(grid_results) + 1]] <- resumen
}

# üìä Tabla final ordenada por F1
pesos_optimos <- bind_rows(grid_results) %>% arrange(desc(f1))
print(pesos_optimos)

# üß† ENTRENAMIENTO FINAL DE MODELOS COMPLETOS (RF + Logit)
modelo_rf <- ranger(
  formula = factor(pobre) ~ . - id,
  data = train_ext,
  probability = TRUE,
  num.trees = 500,
  mtry = 3,
  min.node.size = 20,
  class.weights = c("0" = 1, "1" = 3),
  seed = 123
)

train_ext_glm <- train_ext %>%
  mutate(pobre = as.numeric(as.character(pobre))) %>%
  select(-id)

modelo_logit <- glm(pobre ~ ., data = train_ext_glm, family = binomial)

# üîÆ PREDICCIONES SOBRE TEST FINAL
probs_rf <- predict(modelo_rf, data = test_ext)$predictions[, "1"]
probs_logit <- predict(modelo_logit, newdata = test_ext %>% select(-id), type = "response")

# üß™ ENSAMBLE √ìPTIMO (seg√∫n pesos √≥ptimos)
prob_final <- 0.9 * probs_rf + 0.1 * probs_logit
preds <- ifelse(prob_final > 0.33, 1, 0)

# üíæ EXPORTAR ARCHIVO FINAL
salida <- tibble(id = test_ext$id, pobre = preds)
write_csv(salida, "predicciones_ensamble_optimo.csv")

cat("‚úÖ Archivo guardado: predicciones_ensamble_optimo.csv
")
cat("üìä Total predichos como pobres:", sum(salida$pobre), "
")
cat("üìä Total predichos como NO pobres:", sum(salida$pobre == 0), "
")
```

## 3.4 XGBoost

XGBoost (Extreme Gradient Boosting) es un algoritmo de boosting basado en √°rboles de decisi√≥n que ha demostrado un excelente rendimiento en tareas de clasificaci√≥n y regresi√≥n. Su eficiencia computacional y capacidad para capturar relaciones complejas lo convierten en una herramienta poderosa para este tipo de tareas. En esta secci√≥n se entrena un modelo XGBoost con validaci√≥n cruzada para determinar el n√∫mero √≥ptimo de iteraciones (`nrounds`) y se selecciona el mejor punto de corte (`cutoff`) basado en el F1 score.

```{r}
# üì¶ CARGA DE PAQUETES
library(tidyverse)
library(janitor)
library(xgboost)
library(purrr)

# üì• PREPARACI√ìN DE DATOS
train_xgb <- train_ext %>%
  mutate(pobre = as.numeric(as.character(pobre))) %>%
  select(-id)

X <- as.matrix(train_xgb %>% select(-pobre))
y <- train_xgb$pobre
dtrain <- xgb.DMatrix(data = X, label = y)

# üîÅ VALIDACI√ìN CRUZADA PARA ELEGIR nrounds
params <- list(
  objective = "binary:logistic",
  eval_metric = "logloss",
  eta = 0.1,
  max_depth = 4,
  subsample = 0.8,
  colsample_bytree = 0.8
)

set.seed(123)
cv_result <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 1000,
  nfold = 5,
  early_stopping_rounds = 20,
  verbose = 1
)

best_nrounds <- cv_result$best_iteration
cat("üå≤ Best nrounds:", best_nrounds, "
")

# üß† ENTRENAMIENTO FINAL
xgb_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = best_nrounds,
  verbose = 1
)

# üéØ AJUSTE DE CUTOFF
probs_train <- predict(xgb_model, newdata = X)
cutoffs <- seq(0.10, 0.50, by = 0.01)

metricas_xgb <- map_dfr(cutoffs, function(cut) {
  pred <- ifelse(probs_train > cut, 1, 0)

  tp <- sum(pred == 1 & y == 1)
  tn <- sum(pred == 0 & y == 0)
  fp <- sum(pred == 1 & y == 0)
  fn <- sum(pred == 0 & y == 1)

  precision <- ifelse(tp + fp == 0, NA, tp / (tp + fp))
  recall <- ifelse(tp + fn == 0, NA, tp / (tp + fn))
  f1 <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0, NA,
               2 * precision * recall / (precision + recall))

  tibble(cutoff = cut, precision, recall, f1)
})

mejor_cutoff <- metricas_xgb %>% arrange(desc(f1)) %>% slice_head(n = 1)
print(mejor_cutoff)

metricas_xgb %>%
  ggplot(aes(x = cutoff, y = f1)) +
  geom_line(color = "blue", size = 1.2) +
  geom_point(size = 1.5) +
  labs(title = "F1 Score vs Cutoff (XGBoost)", x = "Cutoff", y = "F1 Score") +
  theme_minimal()

# üîÆ PREDICCIONES SOBRE TEST
X_test <- test_ext %>%
  select(all_of(colnames(X))) %>%
  as.matrix()

probs_test <- predict(xgb_model, newdata = X_test)
final_cutoff <- mejor_cutoff$cutoff
preds_test <- ifelse(probs_test > final_cutoff, 1, 0)

# üíæ EXPORTAR
submission <- tibble(id = test_ext$id, pobre = preds_test)
write_csv(submission, "predicciones_xgboost.csv")

cat("‚úÖ Archivo guardado: predicciones_xgboost.csv
")
cat("üìä Total pobres predichos:", sum(submission$pobre), "
")
cat("üìä Total NO pobres predichos:", sum(submission$pobre == 0), "
")
```
## 3.5 Stacking: XGBoost + Random Forest

En esta secci√≥n implementamos un modelo de **stacking**, una t√©cnica de ensamblaje que combina m√∫ltiples algoritmos para mejorar el desempe√±o predictivo. Aqu√≠ se mezclan las predicciones de un modelo XGBoost y un Random Forest utilizando un promedio ponderado. Esta estrategia busca capturar lo mejor de ambos mundos: la robustez del RF y la precisi√≥n del XGBoost.

```{r}
library(tidyverse)
library(janitor)
library(xgboost)
library(ranger)
library(purrr)
library(readr)
library(caret)

# üîÅ ENTRENAR MODELO XGBOOST
X <- as.matrix(train_ext %>% select(-id, -pobre))
y <- train_ext$pobre
dtrain <- xgb.DMatrix(data = X, label = y)

params <- list(
  objective = "binary:logistic",
  eval_metric = "logloss",
  eta = 0.1,
  max_depth = 4,
  subsample = 0.8,
  colsample_bytree = 0.8
)

set.seed(123)
cv_xgb <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 1000,
  nfold = 5,
  early_stopping_rounds = 20,
  verbose = 0
)

best_nrounds <- cv_xgb$best_iteration
xgb_model <- xgb.train(params = params, data = dtrain, nrounds = best_nrounds)

# üîÅ ENTRENAR RANDOM FOREST
rf_model <- ranger(
  formula = factor(pobre) ~ . - id,
  data = train_ext,
  probability = TRUE,
  num.trees = 500,
  mtry = 3,
  min.node.size = 20,
  class.weights = c("0" = 1, "1" = 3),
  seed = 123
)

# üîÆ ENSAMBLE
X_test <- as.matrix(test_ext %>% select(all_of(colnames(X))))
probs_xgb <- predict(xgb_model, newdata = X_test)
probs_rf <- predict(rf_model, data = test_ext)$predictions[, "1"]

prob_ensamble <- 0.6 * probs_rf + 0.4 * probs_xgb
preds <- ifelse(prob_ensamble > 0.33, 1, 0)

# Volver a predecir probabilidades sobre el train
X_train <- as.matrix(train_ext %>% select(-id, -pobre))
probs_xgb_train <- predict(xgb_model, newdata = X_train)
probs_rf_train <- predict(rf_model, data = train_ext)$predictions[, "1"]

# Ensamble local con mismos pesos y cutoff
prob_ensamble_train <- 0.6 * probs_rf_train + 0.4 * probs_xgb_train
pred_train <- ifelse(prob_ensamble_train > 0.33, 1, 0)
real_train <- train_ext$pobre

# F1 score
f1_score <- F_meas(factor(pred_train), factor(real_train), relevant = "1")
cat("üìä F1 score local sobre train:", round(f1_score, 4), "
")

# üíæ EXPORTAR ARCHIVO FINAL PARA KAGGLE
submission <- tibble(id = test_ext$id, pobre = preds)
write_csv(submission, "predicciones_ensamble_xgb_rf.csv")

cat("‚úÖ Archivo guardado: predicciones_ensamble_xgb_rf.csv/n")
cat("üìä Total predichos como pobres:", sum(submission$pobre), "/n")
cat("üìä Total predichos como NO pobres:", sum(submission$pobre == 0), "/n")

# üìä COMPARACI√ìN FINAL DE F1 SCORES DE TODOS LOS MODELOS

# F1 del Elastic Net (modelo logit base)
f1_elastic <- f1  # obtenido al validar el modelo logit base

# F1 del CART b√°sico y podado
f1_cart_basico <- f1_cart
f1_cart_podado <- f1_cart_cv

# F1 del ensamblaje RF + Logit
f1_ensamble_rf_logit <- pesos_optimos$f1[1]  # mejor resultado del grid

# F1 del XGBoost (usamos el mejor F1 en entrenamiento con cutoff ajustado)
f1_xgb <- mejor_cutoff$f1

# F1 del stacking (XGBoost + RF)
f1_stacking <- f1_score

# Crear tabla comparativa
f1_comparacion <- tibble::tibble(
  Modelo = c(
    "Elastic Net (logit)",
    "CART b√°sico",
    "CART podado",
    "Ensamble RF + Logit",
    "XGBoost",
    "Stacking (XGB + RF)"
  ),
  F1_Score = c(
    f1_elastic,
    f1_cart_basico,
    f1_cart_podado,
    f1_ensamble_rf_logit,
    f1_xgb,
    f1_stacking
  )
)

# Mostrar tabla
f1_comparacion %>%
  dplyr::arrange(desc(F1_Score)) %>%
  knitr::kable(digits = 4, caption = "Comparaci√≥n de F1 Score entre modelos") %>%
  kableExtra::kable_styling(full_width = FALSE, position = "center")


