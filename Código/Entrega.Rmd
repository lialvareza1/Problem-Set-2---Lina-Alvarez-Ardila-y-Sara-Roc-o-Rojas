---
title: "Predicci√≥n de la pobreza en Colombia - Taller 2 BDML"
author: "Sara Rojas y Lina Alvarez"
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: true
    theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# 1. Introducci√≥n

La pobreza sigue siendo una de las problem√°ticas m√°s relevantes en la formulaci√≥n de pol√≠ticas p√∫blicas en Colombia. Este documento presenta el desarrollo del Taller 2 de la materia Big Data y Machine Learning (ECON4676), cuyo objetivo es construir un modelo predictivo para identificar hogares en situaci√≥n de pobreza, a partir de datos suministrados por el DANE. Usamos algoritmos de clasificaci√≥n y abordamos aspectos como desbalance de clases, tuning de hiperpar√°metros y comparaci√≥n de modelos. La evaluaci√≥n de desempe√±o se realiza con la m√©trica F1-score y las predicciones son validadas en la plataforma Kaggle.

# 2. Datos

#2.01 Instalar paquetes
```{r}
require(pacman)
p_load(tidyverse,
       janitor,
       readr,
       glmnet,
       pROC,
       gridExtra)
```

## 2.1 Descarga de las bases de datos

```{r}
train_p <- read_csv("https://www.dropbox.com/scl/fi/pch52dyx8gilx4rtvmgnw/train_personas.csv?rlkey=tfzax7opjw39va52wf5orz5od&st=aybcoq48&dl=1") %>% clean_names()
train_h <- read_csv("https://www.dropbox.com/scl/fi/kzpccqa6gwtzx0e79iqct/train_hogares.csv?rlkey=ala8b4z6u295zan684zw0zyfb&st=slkkf6kt&dl=1") %>% clean_names()
test_p  <- read_csv("https://www.dropbox.com/scl/fi/bxuc9befzrbt27ajxlpvu/test_personas.csv?rlkey=jh1d6jru4f0jx8ldnqyqshmvh&st=i70qnf7j&dl=1") %>% clean_names()
test_h  <- read_csv("https://www.dropbox.com/scl/fi/sakjsyqp7x7164h68pmam/test_hogares.csv?rlkey=sh8hs0rt1so4cufav0yo8btom&st=t51wnslq&dl=1") %>% clean_names()
```

Este bloque descarga directamente desde Dropbox las cuatro bases proporcionadas para el taller: `train_personas`, `train_hogares`, `test_personas` y `test_hogares`, y las estandariza con `clean_names()` para trabajar con nombres de variables consistentes en R.

## 2.2 Preparaci√≥n de la muestra

```{r}
#-------------------------------------------------------------------------#
# ORGANIZACI√ìN DE LA DATA Y UNI√ìN DE BASES
#-------------------------------------------------------------------------#

# Train:
vars_hogar_extra <- train_p %>%
  mutate(
    edad_laboral = p6040 >= 12 & p6040 <= 65,
    mujer = ifelse(p6020 == 2, 1, 0),
    menor_6 = ifelse(p6040 < 6, 1, 0),
    inactivo_pet = ifelse(edad_laboral, ina, NA)
  ) %>%
  group_by(id) %>%
  summarise(
    n_personas = n(),
    n_ninos = sum(p6040 < 12, na.rm = TRUE),
    n_mayores = sum(p6040 >= 65, na.rm = TRUE),
    prop_ocupados = sum(oc == 1 & edad_laboral, na.rm = TRUE) / sum(edad_laboral, na.rm = TRUE),
    educacion_max = max(p6210, na.rm = TRUE),
    educacion_prom = mean(p6210, na.rm = TRUE),
    edad_jefe = p6040[orden == 1],
    sexo_jefe = p6020[orden == 1],
    n_mujeres = sum(mujer, na.rm = TRUE),
    n_menores_6 = sum(menor_6, na.rm = TRUE),
    ocupados_total = sum(oc == 1, na.rm = TRUE),
    prop_inactivos_pet = sum(inactivo_pet == 1, na.rm = TRUE) / sum(!is.na(inactivo_pet))
  )

train_modelo_ext <- train_h %>%
  left_join(vars_hogar_extra, by = "id")

vars_modelo_ext <- train_modelo_ext %>%
  select(
    pobre,
    n_personas, n_ninos, n_mayores, prop_ocupados,
    educacion_max, educacion_prom, edad_jefe, sexo_jefe,
    n_mujeres, n_menores_6, ocupados_total, prop_inactivos_pet
  ) %>%
  mutate(across(.cols = everything(), .fns = ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))

vars_modelo_ext$pobre = as.factor(vars_modelo_ext$pobre)

# Test:
vars_test_ext <- test_p %>%
  mutate(
    edad_laboral = p6040 >= 12 & p6040 <= 65,
    mujer = ifelse(p6020 == 2, 1, 0),
    menor_6 = ifelse(p6040 < 6, 1, 0),
    inactivo_pet = ifelse(edad_laboral, ina, NA)
  ) %>%
  group_by(id) %>%
  summarise(
    n_personas = n(),
    n_ninos = sum(p6040 < 12, na.rm = TRUE),
    n_mayores = sum(p6040 >= 65, na.rm = TRUE),
    prop_ocupados = sum(oc == 1 & edad_laboral, na.rm = TRUE) / sum(edad_laboral, na.rm = TRUE),
    educacion_max = max(p6210, na.rm = TRUE),
    educacion_prom = mean(p6210, na.rm = TRUE),
    edad_jefe = p6040[orden == 1],
    sexo_jefe = p6020[orden == 1],
    n_mujeres = sum(mujer, na.rm = TRUE),
    n_menores_6 = sum(menor_6, na.rm = TRUE),
    ocupados_total = sum(oc == 1, na.rm = TRUE),
    prop_inactivos_pet = sum(inactivo_pet == 1, na.rm = TRUE) / sum(!is.na(inactivo_pet))
  )

test_modelo_ext <- test_h %>%
  left_join(vars_test_ext, by = "id") %>%
  mutate(across(.cols = -id, .fns = ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))

X_vars_test_ext_full <- model.matrix(~ . - id -1, data = test_modelo_ext)
```
## 2.3 Estad√≠sticas descriptivas y visualizaci√≥n

```{r}
# Este bloque se enfoca √∫nicamente en la creaci√≥n del df para las gr√°ficas exploratorias
# y no ser√° utilizado para el entrenamiento de modelos.

p_load(forcats)

df <- train_p %>%
  group_by(id) %>%
  summarise(
    n_personas = n(),
    mujer = sum(p6020 == 2, na.rm = TRUE),
    hombre = sum(p6020 == 1, na.rm = TRUE),
    ni√±os = sum(p6040 < 12, na.rm = TRUE),
    mayores = sum(p6040 >= 65, na.rm = TRUE),
    ocupados = sum(p6240 == 1, na.rm = TRUE),
    educ_sup = sum(p6210 %in% c(8, 9), na.rm = TRUE),
    edad_promedio = mean(p6040, na.rm = TRUE),
    nivel_educativo = mean(p6210, na.rm = TRUE)
  ) %>%
  mutate(prop_ocupados = ocupados / n_personas)

df <- left_join(train_h, df, by = "id")
glimpse(df)

# Gr√°ficos: secciones comentadas cada tres visualizaciones

# Tama√±o del hogar, n√∫mero de ocupados y nivel educativo
p1 <- ggplot(df, aes(x = factor(pobre), y = n_personas)) +
  geom_boxplot(fill = "#0072CE", alpha = 0.6) +
  labs(x = "pobre", y = "Tama√±o del hogar") +
  theme_minimal()

p2 <- ggplot(df, aes(x = factor(pobre), y = ocupados)) +
  geom_boxplot(fill = "#E30613", alpha = 0.6) +
  labs(x = "pobre", y = "Ocupados") +
  theme_minimal()

p3 <- ggplot(df, aes(x = factor(pobre), y = nivel_educativo)) +
  geom_boxplot(fill = "#F4C300", alpha = 0.6) +
  labs(x = "pobre", y = "Nivel educativo") +
  theme_minimal()

# Edad promedio, proporci√≥n ocupados y distribuci√≥n del ingreso per c√°pita
p4 <- ggplot(df, aes(x = factor(pobre), y = edad_promedio)) +
  geom_boxplot(fill = "#F7A600", alpha = 0.6) +
  labs(x = "pobre", y = "Edad promedio") +
  theme_minimal()

p5 <- ggplot(df, aes(x = factor(pobre), y = prop_ocupados)) +
  geom_boxplot(fill = "#A0195B", alpha = 0.6) +
  labs(x = "pobre", y = "Proporci√≥n ocupados") +
  theme_minimal()

p6 <- ggplot(df, aes(x = factor(pobre), y = ingtotug)) +
  geom_violin(fill = "#0072CE", alpha = 0.6) +
  scale_y_log10() +
  labs(x = "pobre", y = "Ingreso per c√°pita (log)") +
  theme_minimal()

# Histogramas de ingreso, nivel educativo y tama√±o del hogar
p7 <- ggplot(df, aes(x = ingtotug, fill = factor(pobre))) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 50) +
  scale_x_log10() +
  labs(x = "Ingreso per c√°pita (log)", fill = "pobre") +
  theme_minimal()

p8 <- df %>%
  count(nivel_educativo) %>%
  filter(!is.na(nivel_educativo)) %>%
  mutate(nivel_educativo = fct_reorder(as.factor(nivel_educativo), n, .desc = TRUE)) %>%
  ggplot(aes(x = nivel_educativo, y = n)) +
  geom_bar(stat = "identity", fill = "#0072CE") +
  labs(x = "Nivel educativo promedio", y = "Frecuencia") +
  theme_minimal()

p9 <- ggplot(df, aes(x = n_personas)) +
  geom_histogram(fill = "#A0195B", bins = 30) +
  labs(x = "Tama√±o del hogar", y = "Frecuencia") +
  theme_minimal()
install.packages("gridExtra")
library(gridExtra)
grid.arrange(p1, p2, p3, p4, p5, p6, ncol = 3)

```
# 3 Modelos
## 3.1 Elastic Net Regularizado

El modelo Elastic Net combina las penalizaciones L1 (Lasso) y L2 (Ridge), lo que permite realizar selecci√≥n de variables y reducir el sobreajuste, especialmente √∫til cuando hay colinealidad. Aqu√≠ se utiliza un `alpha = 0.5` que balancea ambos extremos. Se emplea validaci√≥n cruzada con 5 folds para encontrar el `lambda` √≥ptimo, evaluando el desempe√±o con el √°rea bajo la curva (AUC).

```{r}
X_ext <- model.matrix(pobre ~ . -1, data = vars_modelo_ext)
y_ext <- vars_modelo_ext$pobre

set.seed(123)
modelo_elastic_ext <- cv.glmnet(
  x = X_ext,
  y = y_ext,
  family = "binomial",
  alpha = 0.5,
  nfolds = 5,
  type.measure = "auc"
)

plot(modelo_elastic_ext)
modelo_elastic_ext$lambda.min

test_modelo_ext <- test_h %>%
  left_join(vars_test_ext, by = "id") %>%
  mutate(across(.cols = -id, .fns = ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))

X_vars_test_ext_full <- model.matrix(~ . - id -1, data = test_modelo_ext)

missing_cols <- setdiff(colnames(X_ext), colnames(X_vars_test_ext_full))
for (col in missing_cols) {
  X_vars_test_ext_full <- cbind(X_vars_test_ext_full, setNames(data.frame(rep(0, nrow(X_vars_test_ext_full))), col))
}
X_vars_test_ext <- X_vars_test_ext_full[, colnames(X_ext)]

test_modelo_ext$prob_pred <- as.numeric(predict(modelo_elastic_ext, newx = X_vars_test_ext, s = "lambda.min", type = "response"))
test_modelo_ext$pobre <- ifelse(test_modelo_ext$prob_pred > 0.5, 1, 0)

```

### üìä CURVA ROC Y AUC

```{r}
roc_elastic_ext <- roc(response = as.numeric(test_modelo_ext$pobre),
                       predictor = test_modelo_ext$prob_pred,
                       levels = c(0,1))

auc(roc_elastic_ext)

plot(roc_elastic_ext, col = "darkgreen", lwd = 2, main = "ROC - Elastic Net Extendido")
abline(a = 0, b = 1, lty = 2, col = "gray")
```

### üíæ GUARDAR PREDICCIONES EN CSV

```{r}
predicciones_ext <- test_modelo_ext %>% select(id, pobre)
write_csv(predicciones_ext, "predicciones_elastic_net_extendido.csv")
```

## 3.2 √Årboles de Clasificaci√≥n (CART)

Los √°rboles de decisi√≥n tipo CART (Classification and Regression Trees) son modelos de clasificaci√≥n que permiten segmentar los datos a trav√©s de reglas de decisi√≥n simples. Una de sus principales ventajas es su **interpretabilidad**, ya que permiten visualizar el proceso de clasificaci√≥n de manera jer√°rquica. En este caso, utilizamos CART para predecir la condici√≥n de pobreza del hogar. A continuaci√≥n se presenta la implementaci√≥n completa:
  
  Se cargan las librer√≠as necesarias:
  - `caret`: para entrenamiento y validaci√≥n cruzada.
- `rpart`: para construir √°rboles de clasificaci√≥n.
- `rpart.plot`: para visualizar los √°rboles de decisi√≥n.
- `MLmetrics`: para calcular m√©tricas como el F1 Score.

```{r}
# Cargar librer√≠as necesarias
p_load(caret,
       rpart,
       rpart.plot,
       MLmetrics)


# Entrenamiento inicial del CART b√°sico
modelo_cart <- rpart(
  formula = pobre ~ .,
  data = vars_modelo_ext,
  method = "class",
  parms = list(split = "gini"),
  control = rpart.control(cp = 0.01, minsplit = 20)
)

# Visualizaci√≥n del √°rbol inicial
rpart.plot(
  modelo_cart,
  type = 2,
  extra = 104,
  under = TRUE,
  fallen.leaves = TRUE,
  box.palette = "Blues"
)

# Evaluaci√≥n del modelo
pred_entrenamiento <- predict(modelo_cart, newdata = vars_modelo_ext, type = "class")

f1_cart <- F1_Score(
  y_pred = as.character(pred_entrenamiento),
  y_true = as.character(vars_modelo_ext$pobre),
  positive = "1"
)

print(paste("F1 Score del CART en train:", round(f1_cart, 4)))

# Segundo intento: CART con tuning de hiperpar√°metros
set.seed(123)

ctrl <- trainControl(
  method = "cv",
  number = 5,
  summaryFunction = defaultSummary,
  classProbs = TRUE
)

grid <- expand.grid(cp = seq(0.0001, 0.05, by = 0.002))

vars_modelo_ext <- vars_modelo_ext %>%
  mutate(pobre = factor(pobre, levels = c(0, 1), labels = c("no", "si")))

modelo_cart_cv <- train(
  pobre ~ .,
  data = vars_modelo_ext,
  method = "rpart",
  trControl = ctrl,
  tuneGrid = grid,
  metric = "Accuracy"
)

print(modelo_cart_cv)
plot(modelo_cart_cv)

# √Årbol final podado
rpart.plot(
  modelo_cart_cv$finalModel,
  type = 2,
  extra = 104,
  under = TRUE,
  fallen.leaves = TRUE,
  box.palette = "Blues"
)

# Predicci√≥n y evaluaci√≥n final
pred_entrenamiento <- predict(modelo_cart_cv, newdata = vars_modelo_ext)

f1_cart_cv <- F1_Score(
  y_pred = pred_entrenamiento,
  y_true = vars_modelo_ext$pobre,
  positive = "si"
)

print(paste("F1 Score del CART podado (train):", round(f1_cart_cv, 4)))

confusionMatrix(
  data = pred_entrenamiento,
  reference = vars_modelo_ext$pobre,
  mode = "everything",
  positive = "si"
)
```
## 3.3 Ensamble de Logit y Random Forest

En esta secci√≥n implementamos un modelo de ensamblaje que combina las predicciones de un modelo de regresi√≥n log√≠stica (logit) y un modelo de bosque aleatorio (Random Forest). El objetivo es aprovechar la capacidad explicativa y lineal del logit con la flexibilidad y poder de captura no lineal del Random Forest. Se ajustan ambos modelos, se realiza una combinaci√≥n ponderada de las probabilidades, y se optimiza el peso del ensamblaje mediante validaci√≥n cruzada para maximizar el F1-score.

```{r}
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üì¶ CARGA DE PAQUETAS
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üì¶ Cargar librer√≠as
library(tidyverse)
library(ranger)

# üéØ Entrenamiento del modelo Random Forest
modelo_rf <- ranger(
  formula = pobre ~ .,
  data = vars_modelo_ext,
  probability = TRUE,
  num.trees = 100,
  mtry = 3,
  min.node.size = 20,
  class.weights = c("0" = 1, "1" = 3),
  seed = 123
)

# üéØ Entrenamiento del modelo Logit
modelo_logit <- glm(pobre ~ ., data = vars_modelo_ext, family = binomial)

# üîÆ Predicci√≥n sobre el test (probabilidades)
probs_logit <- predict(modelo_logit, newdata = vars_test_ext, type = "response")
rf_pred <- predict(modelo_rf, data = vars_test_ext)$predictions
probs_rf <- if ("1" %in% colnames(rf_pred)) rf_pred[, "1"] else rf_pred[, 1]

# ü§ù Ensamble inicial de probabilidades (60% RF, 40% Logit)
prob_ensamble <- 0.6 * probs_rf + 0.4 * probs_logit
cutoff_final <- 0.33
preds <- ifelse(prob_ensamble > cutoff_final, 1, 0)

# üéØ Preparaci√≥n para validaci√≥n cruzada del peso del ensamble
set.seed(123)
k <- 5
n <- nrow(vars_modelo_ext)
folds <- sample(rep(1:k, length.out = n))
rf_weights <- seq(0.1, 0.9, by = 0.1)
cutoff_ensamble <- 0.33
grid_results <- list()

# üîÅ Grid Search por el mejor peso
for (w in rf_weights) {
  logit_w <- 1 - w
  fold_metrics <- list()
  
  for (fold in 1:k) {
    train_fold <- vars_modelo_ext[folds != fold, ]
    val_fold   <- vars_modelo_ext[folds == fold, ]
    
    modelo_rf <- ranger(
      formula = pobre ~ .,
      data = train_fold,
      probability = TRUE,
      num.trees = 100,
      mtry = 3,
      min.node.size = 20,
      class.weights = c("0" = 1, "1" = 3),
      seed = 123
    )
    rf_val_pred <- predict(modelo_rf, data = val_fold)$predictions
    probs_rf <- if ("1" %in% colnames(rf_val_pred)) rf_val_pred[, "1"] else rf_val_pred[, 1]
    
    modelo_logit <- glm(pobre ~ ., data = train_fold, family = binomial)
    probs_logit <- predict(modelo_logit, newdata = val_fold, type = "response")
    
    prob_final <- w * probs_rf + logit_w * probs_logit
    pred <- ifelse(prob_final > cutoff_ensamble, 1, 0)
    real <- val_fold$pobre
    
    tp <- sum(pred == 1 & real == 1)
    tn <- sum(pred == 0 & real == 0)
    fp <- sum(pred == 1 & real == 0)
    fn <- sum(pred == 0 & real == 1)
    
    precision <- ifelse(tp + fp == 0, NA, tp / (tp + fp))
    recall <- ifelse(tp + fn == 0, NA, tp / (tp + fn))
    f1 <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0, NA,
                 2 * precision * recall / (precision + recall))
    
    fold_metrics[[fold]] <- tibble(fold, precision, recall, f1)
  }
  
  resumen <- bind_rows(fold_metrics) %>%
    summarise(across(precision:f1, mean, na.rm = TRUE)) %>%
    mutate(rf_weight = w, logit_weight = logit_w)
  
  grid_results[[length(grid_results) + 1]] <- resumen
}

# üìä Tabla final ordenada por F1
pesos_optimos <- bind_rows(grid_results) %>% arrange(desc(f1))
print(pesos_optimos)

# üîÆ Predicci√≥n final usando el mejor peso
mejor_peso_rf <- pesos_optimos$rf_weight[1]
mejor_peso_logit <- pesos_optimos$logit_weight[1]

probs_logit_final <- predict(modelo_logit, newdata = vars_test_ext, type = "response")
rf_pred_final <- predict(modelo_rf, data = vars_test_ext)$predictions
probs_rf_final <- if ("1" %in% colnames(rf_pred_final)) rf_pred_final[, "1"] else rf_pred_final[, 1]

prob_final <- mejor_peso_rf * probs_rf_final + mejor_peso_logit * probs_logit_final
preds <- ifelse(prob_final > 0.33, 1, 0)

# üíæ Exportar predicciones a archivo .csv
salida <- tibble(id = vars_test_ext$id, pobre = preds)
write_csv(salida, "predicciones_ensamble_optimo.csv")

cat("‚úÖ Archivo guardado: predicciones_ensamble_optimo.csv\n")
cat("üìä Total predichos como pobres:", sum(salida$pobre), "\n")
cat("üìä Total predichos como NO pobres:", sum(salida$pobre == 0), "\n")

```
XGBoost (Extreme Gradient Boosting) es un algoritmo de boosting basado en √°rboles de decisi√≥n que ha demostrado un excelente rendimiento en tareas de clasificaci√≥n y regresi√≥n. Su eficiencia computacional y capacidad para capturar relaciones complejas lo convierten en una herramienta poderosa para este tipo de tareas. En esta secci√≥n se entrena un modelo XGBoost con validaci√≥n cruzada para determinar el n√∫mero √≥ptimo de iteraciones (nrounds) y se selecciona el mejor punto de corte (cutoff) basado en el F1 score.

```{r}
# üì¶ CARGA DE PAQUETES

p_load(janitor,
       xgboost,
       purrr)


# üì• PREPARACI√ìN DE DATOS
train_xgb <- vars_modelo_ext %>%
  filter(!is.na(pobre)) %>%
  mutate(pobre = as.numeric(as.character(pobre))) %>%  # si es factor
  mutate(pobre = ifelse(pobre == 1, 1, 0))              # fuerza a 0 y 1


X <- as.matrix(train_xgb %>% select(-pobre))
y <- train_xgb$pobre
dtrain <- xgb.DMatrix(data = X, label = y)

# üîÅ VALIDACI√ìN CRUZADA PARA ELEGIR nrounds
params <- list(
  objective = "binary:logistic",
  eval_metric = "logloss",
  eta = 0.1,
  max_depth = 4,
  subsample = 0.8,
  colsample_bytree = 0.8
)

set.seed(123)
cv_result <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 1000,
  nfold = 5,
  early_stopping_rounds = 20,
  verbose = 1
)

best_nrounds <- cv_result$best_iteration
cat("üå≤ Best nrounds:", best_nrounds, "
")

# üß† ENTRENAMIENTO FINAL
xgb_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = best_nrounds,
  verbose = 1
)

# üéØ AJUSTE DE CUTOFF
probs_train <- predict(xgb_model, newdata = X)
cutoffs <- seq(0.10, 0.50, by = 0.01)

metricas_xgb <- map_dfr(cutoffs, function(cut) {
  pred <- ifelse(probs_train > cut, 1, 0)
  
  tp <- sum(pred == 1 & y == 1)
  tn <- sum(pred == 0 & y == 0)
  fp <- sum(pred == 1 & y == 0)
  fn <- sum(pred == 0 & y == 1)
  
  precision <- ifelse(tp + fp == 0, NA, tp / (tp + fp))
  recall <- ifelse(tp + fn == 0, NA, tp / (tp + fn))
  f1 <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0, NA,
               2 * precision * recall / (precision + recall))
  
  tibble(cutoff = cut, precision, recall, f1)
})

mejor_cutoff <- metricas_xgb %>% arrange(desc(f1)) %>% slice_head(n = 1)
print(mejor_cutoff)

metricas_xgb %>%
  ggplot(aes(x = cutoff, y = f1)) +
  geom_line(color = "blue", size = 1.2) +
  geom_point(size = 1.5) +
  labs(title = "F1 Score vs Cutoff (XGBoost)", x = "Cutoff", y = "F1 Score") +
  theme_minimal()

# üîÆ PREDICCIONES SOBRE TEST
X_test <- vars_test_ext %>%
  select(all_of(colnames(X))) %>%
  as.matrix()

probs_test <- predict(xgb_model, newdata = X_test)
final_cutoff <- mejor_cutoff$cutoff
preds_test <- ifelse(probs_test > final_cutoff, 1, 0)

# üíæ EXPORTAR
submission <- tibble(id = vars_test_ext$id, pobre = preds_test)
write_csv(submission, "predicciones_xgboost.csv")

cat("‚úÖ Archivo guardado: predicciones_xgboost.csv
")
cat("üìä Total pobres predichos:", sum(submission$pobre), "
")
cat("üìä Total NO pobres predichos:", sum(submission$pobre == 0), "
")

```

